# -*- coding: utf-8 -*-
"""GenAI_3rd_Lab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kuly6npSFXduQmWgYDWLMqQfVPIYHfjg
"""

# prompt: Explain me all the above code

# Import necessary libraries
import tensorflow as tf  # Deep learning framework
from tensorflow.keras import datasets, layers, models  # Keras API for building neural networks
import matplotlib.pyplot as plt  # For plotting images
import numpy as np  # For numerical operations
from sklearn.metrics import confusion_matrix, classification_report  # For evaluating model performance

# Load CIFAR-10 dataset
(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()

# Explore dataset shape and labels
X_train.shape  # (50000, 32, 32, 3) - 50k training images, 32x32 pixels, 3 color channels
X_test.shape   # (10000, 32, 32, 3) - 10k test images
y_train.shape  # (50000, 1) - labels for training images
y_train[:5]    # Shows first 5 labels (as 2D array)

# Reshape labels to 1D array
y_train = y_train.reshape(-1,)
y_train[:5]    # Shows first 5 labels (now as 1D array)
y_test = y_test.reshape(-1,)

# Define class names for better understanding
classes = ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]

# Function to plot a sample image with its label
def plot_sample(X, y, index):
    plt.figure(figsize=(15, 2))
    plt.imshow(X[index])
    plt.xlabel(classes[y[index]])

# Plot a couple of sample images
plot_sample(X_train, y_train, 0)
plot_sample(X_train, y_train, 1)

# Normalize pixel values to range [0, 1]
X_train = X_train / 255.0
X_test = X_test / 255.0

# Build a simple Artificial Neural Network (ANN)
ann = models.Sequential([
    layers.Flatten(input_shape=(32, 32, 3)),  # Flatten input images
    layers.Dense(3000, activation='relu'),    # Fully connected layer with 3000 neurons, ReLU activation
    layers.Dense(1000, activation='relu'),    # Another fully connected layer with 1000 neurons
    layers.Dense(10, activation='softmax')     # Output layer with 10 neurons (for 10 classes), softmax activation
])

# Compile the ANN model
ann.compile(optimizer='SGD',                # Stochastic Gradient Descent optimizer
              loss='sparse_categorical_crossentropy',  # Loss function for multi-class classification
              metrics=['accuracy'])             # Track accuracy during training

# Train the ANN model
ann.fit(X_train, y_train, epochs=5)          # Train for 5 epochs

# Make predictions on test set using ANN
y_pred = ann.predict(X_test)
y_pred_classes = [np.argmax(element) for element in y_pred]  # Get predicted class indices

# Evaluate ANN performance
print("Classification Report: \n", classification_report(y_test, y_pred_classes))

# Build a Convolutional Neural Network (CNN)
cnn = models.Sequential([
    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),  # Convolutional layer
    layers.MaxPooling2D((2, 2)),                                                              # Max pooling layer

    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),  # Another convolutional layer
    layers.MaxPooling2D((2, 2)),                                                              # Max pooling layer

    layers.Flatten(),                                                 # Flatten feature maps
    layers.Dense(64, activation='relu'),                               # Fully connected layer
    layers.Dense(10, activation='softmax')                            # Output layer
])

# Compile the CNN model
cnn.compile(optimizer='adam',                 # Adam optimizer
              loss='sparse_categorical_crossentropy',  # Loss function
              metrics=['accuracy'])             # Track accuracy

# Train the CNN model
cnn.fit(X_train, y_train, epochs=10)         # Train for 10 epochs

# Evaluate CNN performance
cnn.evaluate(X_test, y_test)

# Make predictions on test set using CNN
y_pred = cnn.predict(X_test)
y_pred[:5]                                    # Show raw prediction probabilities for first 5 samples

# Get predicted class indices
y_classes = [np.argmax(element) for element in y_pred]
y_classes[:5]                                 # Show predicted classes for first 5 samples

# Compare with actual labels
y_test[:5]

# Visualize a test sample and its prediction
plot_sample(X_test, y_test, 3)
classes[y_classes[3]]                         # Print predicted class name

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np

(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()
X_train.shape

X_test.shape

y_train.shape

y_train[:5]

y_train = y_train.reshape(-1,)
y_train[:5]

y_test = y_test.reshape(-1,)

classes = ["airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck"]

def plot_sample(X, y, index):
    plt.figure(figsize = (15,2))
    plt.imshow(X[index])
    plt.xlabel(classes[y[index]])

import matplotlib.pyplot as plt

# Assuming 'train_images' is part of a dataset like CIFAR-10, you would load it like this:
from keras.datasets import cifar10
(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()

plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(classes[train_labels[i][0]]) # Use 'classes' instead of 'class_names' and extract the integer label
plt.show()

!pip install tensorflow
import tensorflow as tf
from tensorflow import keras

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10)
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

plot_sample(X_train, y_train, 1)

plot_sample(X_train, y_train, 2)

X_train = X_train / 255.0
X_test = X_test / 255.0

ann = models.Sequential([
        layers.Flatten(input_shape=(32,32,3)),
        layers.Dense(3000, activation='relu'),
        layers.Dense(1000, activation='relu'),
        layers.Dense(10, activation='softmax')
    ])

ann.compile(optimizer='SGD',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

ann.fit(X_train, y_train, epochs=5)

from sklearn.metrics import confusion_matrix , classification_report
import numpy as np
y_pred = ann.predict(X_test)
y_pred_classes = [np.argmax(element) for element in y_pred]

print("Classification Report: \n", classification_report(y_test, y_pred_classes))

cnn = models.Sequential([
    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])
cnn.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
cnn.fit(X_train, y_train, epochs=10)

cnn.evaluate(X_test,y_test)

y_pred = cnn.predict(X_test)
y_pred[:5]

y_classes = [np.argmax(element) for element in y_pred]
y_classes[:5]

y_test[:5]

plot_sample(X_test, y_test,3)

classes[y_classes[3]]

# prompt: Find accuracy of the above model

_, accuracy = cnn.evaluate(X_test, y_test)
print('Accuracy: {:.2f}%'.format(accuracy * 100))